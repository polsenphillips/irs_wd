{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_urls():\n",
    "    urls = []\n",
    "    url = \"https://apps.irs.gov/app/picklist/list/writtenDeterminations.html?resultsPerPage=200&sortColumn=number&indexOfFirstRow=0&criteria=&value=&isDescending=true\"\n",
    "    r = requests.get(url)\n",
    "    iterator = 0\n",
    "    while r.status_code == 200:\n",
    "        urls.append(url)\n",
    "        iterator += 200\n",
    "        url = \"https://apps.irs.gov/app/picklist/list/writtenDeterminations.html?resultsPerPage=200&sortColumn=number&indexOfFirstRow=\"+ str(iterator) + \"&criteria=&value=&isDescending=true\"\n",
    "        r = requests.get(url)    \n",
    "    print(\"URLS generated.\")    \n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://apps.irs.gov/app/picklist/list/writtenDeterminations.html?resultsPerPage=200&sortColumn=number&indexOfFirstRow=0&criteria=&value=&isDescending=true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_names = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_soup(urls):##Takes a really long time. Maybe use \"lxml\" argument?\n",
    "    table = []\n",
    "    for url in urls:\n",
    "        url_req = requests.get(url)\n",
    "        soup = BeautifulSoup(url_req.content, 'html.parser')\n",
    "        target_info = soup.findAll(True, {'class':['odd', 'even']})\n",
    "        for row in target_info:\n",
    "            values = row.findAll(\"td\")\n",
    "            url = values[0].find(\"a\").get(\"href\")\n",
    "            number = values[0].find(\"a\").getText(strip = True)\n",
    "            uilc = values[1].getText(strip = True)\n",
    "            subject = values[2].getText(strip = True).replace(\"&quot;\", \"'\")\n",
    "            release_date = values[3].getText(strip = True)\n",
    "            table.append([url, number, uilc, subject, release_date])  \n",
    "    print(\"Table populated.\")    \n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'table' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-316f1bfdb339>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'table' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data = table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def add_header():\n",
    "    df.columns = [\"url\", \"number\", \"uilc\", \"subject\", \"release_date\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    parse_soup(generate_urls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    parse_soup(generate_urls())\n",
    "    \n",
    "    add_header()\n",
    "    df.to_csv(\"written_determinations_{0}.csv\".format(str(datetime.date.today())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
